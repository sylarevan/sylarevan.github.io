<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>Interactive perception - Sylvain Argentieri</title><meta name="description" content="Most of the existing works dealing with robot perception (and this includes my own on robot audition!) rely on the&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://my.sylar.org/interactive-perception/"><link rel="alternate" type="application/atom+xml" href="https://my.sylar.org/feed.xml"><link rel="alternate" type="application/json" href="https://my.sylar.org/feed.json"><meta property="og:title" content="Interactive perception"><meta property="og:site_name" content="Sylvain Argentieri"><meta property="og:description" content="Most of the existing works dealing with robot perception (and this includes my own on robot audition!) rely on the&hellip;"><meta property="og:url" content="https://my.sylar.org/interactive-perception/"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://my.sylar.org/media/website/favicon.png" type="image/png"><link rel="stylesheet" href="https://my.sylar.org/assets/css/fontawesome-all.min.css?v=bbcde81f26378440dac4c3d195714389"><link rel="stylesheet" href="https://my.sylar.org/assets/css/style.css?v=d64ad9475236a06f0b3299477ac3c224"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://my.sylar.org/interactive-perception/"},"headline":"Interactive perception","datePublished":"2022-02-19T11:32","dateModified":"2022-02-20T18:39","description":"Most of the existing works dealing with robot perception (and this includes my own on robot audition!) rely on the&hellip;","author":{"@type":"Person","name":"Sylvain Argentieri","url":"https://my.sylar.org/authors/sylvain-argentieri/"},"publisher":{"@type":"Organization","name":"Sylvain Argentieri"}}</script></head><body class="is-preload"><div id="wrapper"><div id="main"><div class="inner"><header id="header"><a class="logo" href="https://my.sylar.org/"><strong>Sylvain Argentieri</strong></a></header><article class="post"><header class="main post__header"><h1>Interactive perception</h1></header><div class="post__inner post__entry"><figure class="post__image post__image--center"><img loading="lazy" src="https://my.sylar.org/media/posts/4/featured_hu1f9c18600ed1f34dbab83b4d59492802_159577_540x0_resize_lanczos_2.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://my.sylar.org/media/posts/4/responsive/featured_hu1f9c18600ed1f34dbab83b4d59492802_159577_540x0_resize_lanczos_2-xs.png 300w, https://my.sylar.org/media/posts/4/responsive/featured_hu1f9c18600ed1f34dbab83b4d59492802_159577_540x0_resize_lanczos_2-sm.png 480w, https://my.sylar.org/media/posts/4/responsive/featured_hu1f9c18600ed1f34dbab83b4d59492802_159577_540x0_resize_lanczos_2-md.png 768w" alt="" width="540" height="196"></figure><p>Most of the existing works dealing with robot perception (and this includes my own on robot audition!) rely on the traditional, somewhat historical, following scheme (a.k.a. <strong>the perceive/plan/act scheme</strong>):</p><ul><li>first, the robot reads and understands its sensations on the basis on a priori models given by the engineers (for instance, auditory, camera, laser, etc. models, trying to make the bridge between the raw sensors outputs and its high level interpretation)</li><li>then, the system plan its action inside a generally well-known environment, whose characteristics are often identified beforehand</li><li>finally, the action is actually performed by controlling the joints thanks to geometric/cinematic/dynamic models and controllers.</li></ul><figure class="post__image post__image--center"><img loading="lazy" src="https://my.sylar.org/media/posts/4/sense-plan-act.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://my.sylar.org/media/posts/4/responsive/sense-plan-act-xs.png 300w, https://my.sylar.org/media/posts/4/responsive/sense-plan-act-sm.png 480w, https://my.sylar.org/media/posts/4/responsive/sense-plan-act-md.png 768w" alt="" width="873" height="203"></figure><p>This very generic approach do work pretty well! As long as your models (of the robot, its sensors, the world, etc.) do fit pretty well the reality for the given task, quite amazing results can be obtained. But being able to deal with incomplete models (<em>and they always are incomplete!</em>), being able to face unpredictable situations where all your models can no longer apply is still a very difficult task. One solution could consist in questioning the aforementioned perception architecture. One could indeed envisage a new way to deal with perception where this ability is no longer somewhat given a priori by the designer of the system, but instead built and discovered by the robot, not from the raw sensory signals (i.e. the outputs od its sensors), but from the sensorimotor flow (i.e. the data made of the data coming from extero and/or proprioceptive sensors, and of the commands of the joints). Then, the previous architecture turns into</p><figure class="post__image post__image--center"><img loading="lazy" src="https://my.sylar.org/media/posts/4/sensorimotor-approach.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://my.sylar.org/media/posts/4/responsive/sensorimotor-approach-xs.png 300w, https://my.sylar.org/media/posts/4/responsive/sensorimotor-approach-sm.png 480w, https://my.sylar.org/media/posts/4/responsive/sensorimotor-approach-md.png 768w" alt="" width="916" height="238"></figure><p>In this line of research, the question of the emergence of internal representation of the robot interaction in its own environment is a central issue. It is indeed only on the basis on these representations that the robot will be able to plan and act in its environment (and not on <em>a priori</em> models like in previous approaches). This question is absolutely fundamental when trying to build robot with autonomy and adaptability capabilities, which are mandatory capabilities in modern application of Robotics.</p><hr><p>I chose to work on those topics through the <em>sensorimotor contingencies theory</em>, that explains that perceiving is analog to the discovering of stable relations (i.e. <em>contingencies</em>) linking motors and sensory events. Then characterizing these invariants (that is, determining precisely <strong>what they are</strong> and <strong>what are their properties</strong>) might help to investigate how internal representations built thanks to them could allow a robot to infer spatial structures without almost no a priori. For that purpose, we already tackled some of these aspects through two main contributions, mainly dealt with from a theoretical (mathematical) point of view:</p><ul><li><a href="https://my.sylar.org/space-dimension-estimation/">space dimension estimation</a></li><li>structuration of the sensorimotor flow:<ul><li>internal representation of the body</li><li>internal representation of the agent working space</li><li>structuration of the agent actions through sensory prediction</li><li>emergence of a subjective sensory continuity</li></ul></li></ul></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on February 20, 2022</p></footer></article></div></div><div id="sidebar"><div class="inner"><nav id="menu"><header class="major"><h2>Menu</h2></header><ul><li><a href="https://my.sylar.org/biography/" target="_self">Home</a></li><li class="active-parent has-submenu"><a href="https://my.sylar.org/research-2/" target="_self" aria-haspopup="true" class="opener">Research</a><ul class="submenu level-2" aria-hidden="true"><li><a href="https://my.sylar.org/research-2/" target="_self">Overview</a></li><li class="active"><a href="https://my.sylar.org/interactive-perception/" target="_self">Interactive perception</a></li><li><a href="https://my.sylar.org/robot-audition/" target="_self">Robot audition</a></li></ul></li><li><a href="https://my.sylar.org/publications/" target="_self">Publications</a></li><li><a href="https://my.sylar.org/people/" target="_self">People</a></li><li class="has-submenu"><a href="https://my.sylar.org/overview/" target="_self" aria-haspopup="true" class="opener">Teaching</a><ul class="submenu level-2" aria-hidden="true"><li><a href="https://my.sylar.org/overview/" target="_self">Overview</a></li><li><a href="https://my.sylar.org/overview/" target="_self">Digital signal processing</a></li><li><a href="https://my.sylar.org/overview/" target="_self">ROS and experimental robotics</a></li><li><a href="https://my.sylar.org/overview/" target="_self">Sound source localization</a></li><li><a href="https://my.sylar.org/overview/" target="_self">Sensorimotor approaches to perception</a></li></ul></li><li><a href="https://my.sylar.org/tools/" target="_self">Tools</a></li></ul></nav><section><header class="major"><h2>Get in touch</h2></header><p>You can find me <a href="https://osm.org/go/0BOd4gUuH?m=" target="_blank" rel="noopener">at ISIR</a>, office J02, or in the Master department, <a href="https://osm.org/go/0BOd4ggYU?m=">Esclangon building</a>, 2nd floor, office 219 (Faculty of Science &amp; Engineering, Sorbonne Université).</p><ul class="contact"><li class="icon solid fa-envelope"><a href="mailto:sylvain.argentieri_AT_sorbonne-universite.fr">my email</a></li><li class="icon solid fa-phone">(+33) 1 44 27 63 55</li><li class="icon solid fa-home">Sorbonne Université<br>Pyramide ISIR - T55/65, bureau J02<br>4 place Jussieu<br>75005 Paris, France</li></ul></section><footer id="footer"><p class="copyright">© Sylvain Argentieri - All rights reserved<a href="https://getpublii.com" target="_blank" rel="noopener"></a></p></footer></div></div></div><script src="https://my.sylar.org/assets/js/jquery.min.js?v=7c14a783dfeb3d238ccd3edd840d82ee"></script><script src="https://my.sylar.org/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://my.sylar.org/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://my.sylar.org/assets/js/util.min.js?v=cbdaf7c20ac2883c77ae23acfbabd47e"></script><script src="https://my.sylar.org/assets/js/main.min.js?v=448f4c9d4b4c374766a1cb76c3d88048"></script><script>var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};</script></body></html>