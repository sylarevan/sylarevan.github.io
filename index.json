[{"authors":["sylvain"],"categories":null,"content":"My research interests are mainly focused on active/interactive perception, i.e. understanding how perception and action are tighlty linked together inside the sensorimotor flow. My approach consists in studying sensorimotor contingencies (i.e. invariants) whose mathematical structure can explain how a naive robot can understand, by itself, the structure of its interaction with the environment.\nI have also worked on Robot Audition (well, I still do sometimes), especially within the binaural paradigm. In Robotics, using only two microphones with a head is a challenging task when dealing with auditory scene analysis in realistic environments involving noises, reverberations, etc. On this topic, I have mainly worked on sound source localization, but also on active audition, mixing audition with the robot movement to better the scene analysis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1577914833,"objectID":"37e93e9705d6fa0eb9c2de4d548fe99e","permalink":"https://my.sylar.org/authors/sylvain/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sylvain/","section":"authors","summary":"My research interests are mainly focused on active/interactive perception, i.e. understanding how perception and action are tighlty linked together inside the sensorimotor flow. My approach consists in studying sensorimotor contingencies (i.e. invariants) whose mathematical structure can explain how a naive robot can understand, by itself, the structure of its interaction with the environment.\nI have also worked on Robot Audition (well, I still do sometimes), especially within the binaural paradigm. In Robotics, using only two microphones with a head is a challenging task when dealing with auditory scene analysis in realistic environments involving noises, reverberations, etc.","tags":null,"title":"Sylvain Argentieri","type":"authors"},{"authors":null,"categories":null,"content":"\u0026laquo; back to Robot Audition\nAlmost everyone agree on the physical meaning of interaural cues used for horizontal sound source localization (time delay/phase difference and amplitude difference between the left and right ears signals), there is no clear agreement on the best way to estimate their value. For instance, here is short, clearly incomplete, list of the more classical estimation methods:\nWe then worked during K. Youssef PhD on the comparison between the different definitions proposed in the literature, and on the evaluation of their performances evaluated through a positional classes separation criterion (in azimuth and distance), or in terms of speaker recognition rate. These works demonstrate the robustness of amplitude-bases cues w.r.t. reverberation (ands this was of course expected!), and show that cochlear frequency decomposition outperform classical FFT-based approaches, at a time where they were the most exploited in a Robotics context.\nBinaural sound source localization ","date":1579651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579651200,"objectID":"0753ea81533ab809cc9fe8944f94c51a","permalink":"https://my.sylar.org/projects-details/binaural_cues_characterization/","publishdate":"2020-01-22T00:00:00Z","relpermalink":"/projects-details/binaural_cues_characterization/","section":"projects-details","summary":"\u0026laquo; back to Robot Audition\nAlmost everyone agree on the physical meaning of interaural cues used for horizontal sound source localization (time delay/phase difference and amplitude difference between the left and right ears signals), there is no clear agreement on the best way to estimate their value. For instance, here is short, clearly incomplete, list of the more classical estimation methods:\nWe then worked during K. Youssef PhD on the comparison between the different definitions proposed in the literature, and on the evaluation of their performances evaluated through a positional classes separation criterion (in azimuth and distance), or in terms of speaker recognition rate.","tags":null,"title":"Binaural cues characterization","type":"projects-details"},{"authors":null,"categories":null,"content":"\u0026laquo; back to Robot Audition\nOn the basis on our binaural cues characterization, we exploited an artificial neural network (ANN) to learn and estimate the azimuth and distance of sound sources in the environment. But realistic robotics applications involve dynamic scenarios, where the relative position between the sources and the robot can evolve along time in a reverberant environment. We have then characterized \u0026mdash;during K. Youssef PhD thesis\u0026mdash; the consequences of those changes in relative and absolute positions during the learning and test phases, and studied the generalization capabilities of the proposed ANN. More precisely, we highlighted the sensitivity of the learning phase to acoustical conditions (changes in the reverberation time) and binaural receiver position (different positions in a room). Multiconditionnal learning is thus shown mandatory, even if collecting data in all the various required conditions is far from beaing easy, especially when dealing with a binaural receiver on a mobile robot.\nStructuration of the sensorimotor flow --","date":1579651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579651200,"objectID":"fad4d7493f500dc6cec679acdda41f37","permalink":"https://my.sylar.org/projects-details/source_localization/","publishdate":"2020-01-22T00:00:00Z","relpermalink":"/projects-details/source_localization/","section":"projects-details","summary":"\u0026laquo; back to Robot Audition\nOn the basis on our binaural cues characterization, we exploited an artificial neural network (ANN) to learn and estimate the azimuth and distance of sound sources in the environment. But realistic robotics applications involve dynamic scenarios, where the relative position between the sources and the robot can evolve along time in a reverberant environment. We have then characterized \u0026mdash;during K. Youssef PhD thesis\u0026mdash; the consequences of those changes in relative and absolute positions during the learning and test phases, and studied the generalization capabilities of the proposed ANN.","tags":null,"title":"Binaural sound source localization","type":"projects-details"},{"authors":null,"categories":null,"content":"\u0026laquo; back to Interactive Perception\nWithin the sensorimotor paradigm, the question of space is a primary tremendous issue. While space seems like a kind of universal, homogeneous and isotropic 3D container shared by all of us and our environment, discovering that space actually exists only on the basis on what is actually available \u0026ldquo;from the inside\u0026rdquo; (i.e. the sensorimotor flow) is far from being intuitive. Especially since the sensorimotor flow isn't homogeneous, isotropic and 3D\u0026hellip;\nIn particular, is it possible to rediscover that space out there is a 3D space (at least from our point of view!), and that it can be characterize by 6 independent spatial variables corresponding to the 3 translations and 3 rotations we all know? This important question has already been raised by Henri Poincaré at the end of the 19th century. Philipona showed in 2008 it was possible to recover space dimensionality from the sensorimotor flow, but only from infinitesimal movements. By using non-linear dimensional estimation techniques, we have shown in this paper that, while using realistic movements magnitudes, it was still possible to correctly estimate space dimension.\nStructuration of the sensorimotor flow ","date":1579651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579727422,"objectID":"a5950377182587b6c15df35f6cb446ff","permalink":"https://my.sylar.org/projects-details/dimension_estimation/","publishdate":"2020-01-22T00:00:00Z","relpermalink":"/projects-details/dimension_estimation/","section":"projects-details","summary":"Can we really live in a 3D world?","tags":null,"title":"Space dimension estimation","type":"projects-details"},{"authors":null,"categories":null,"content":"\u0026laquo; back to Interactive Perception\nHaving access to space dimension without any a priori and on the basis on solely the sensorimotor flow is quite interesting, but far from being the most useful knowledge for a robotics agent. Our previous works on these topics were mainly rooted on sensory differential manifold, and the results were thus still dependent to changes in the environment configurations. This is a problem, since the notion of space should not be dependent of what is actually in the agent environment\u0026hellip; We then tried to work on different ways to cope with these changes, first mainly from intuition, and then more formally.\nSpace dimension estimation ","date":1579651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579727422,"objectID":"c3110e7bec55355e43638012dd1c43f1","permalink":"https://my.sylar.org/projects-details/structuration_sensorimotor_flow/","publishdate":"2020-01-22T00:00:00Z","relpermalink":"/projects-details/structuration_sensorimotor_flow/","section":"projects-details","summary":"What is an internal representation?","tags":null,"title":"Structuration of the sensorimotor flow","type":"projects-details"},{"authors":[],"categories":[],"content":" Most of the existing works dealing with robot perception (and this includes my own on robot audition!) rely on the traditional, somewhat historical, following scheme (a.k.a. the perceive/plan/act scheme):\n first, the robot reads and understands its sensations on the basis on a priori models given by the engineers (for instance, auditory, camera, laser, etc. models, trying to make the bridge between the raw sensors outputs and its high level interpretation) then, the system plan its action inside a generally well-known environment, whose characteristics are often identified beforehand finally, the action is actually performed by controlling the joints thanks to geometric/cinematic/dynamic models and controllers.  This very generic approach do work pretty well! As long as your models (of the robot, its sensors, the world, etc.) do fit pretty well the reality for the given task, quite amazing results can be obtained. But being able to deal with incomplete models (and they always are incomplete!), being able to face unpredictable situations where all your models can no longer apply is still a very difficult task. One solution could consist in questioning the aforementioned perception architecture. One could indeed envisage a new way to deal with perception where this ability is no longer somewhat given a priori by the designer of the system, but instead built and discovered by the robot, not from the raw sensory signals (i.e. the outputs od its sensors), but from the sensorimotor flow (i.e. the data made of the data coming from extero and/or proprioceptive sensors, and of the commands of the joints). Then, the previous architecture turns into\nIn this line of research, the question of the emergence of internal representation of the robot interaction in its own environment is a central issue. It is indeed only on the basis on these representations that the robot will be able to plan and act in its environment (and not on a priori models like in previous approaches). This question is absolutely fundamental when trying to build robot with autonomy and adaptability capabilities, which are mandatory capabilities in modern application of Robotics.\n I chose to work on those topics through the sensorimotor contingencies theory, that explains that perceiving is analog to the discovering of stable relations (i.e. contingencies) linking motors and sensory events. Then characterizing these invariants (that is, determining precisely what they are and what are their properties) might help to investigate how internal representations built thanks to them could allow a robot to infer spatial structures without almost no a priori. For that purpose, we already tackled some of these aspects through two main contributions, mainly dealt with from a theoretical (mathematical) point of view:\n space dimension estimation structuration of the sensorimotor flow  ","date":1577896060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579727422,"objectID":"c683ce5e82d6fad1a5dc4aea751be49e","permalink":"https://my.sylar.org/project/interactive_perception/","publishdate":"2020-01-01T17:27:40+01:00","relpermalink":"/project/interactive_perception/","section":"project","summary":"where we deal with what's hidden in the sensorimotor flow","tags":[],"title":"Interactive perception","type":"project"},{"authors":[],"categories":[],"content":"“Blindness separate us from things but deafness from people” said Helen Keller, a famous American author who was the first deafblind person to obtain a Bachelor in Arts, in 1904. And indeed, being able to interpret an auditory scene from a robot is now a required capability when operating with humans, mainly interacting by speech with each others. Auditory scene analysis is a quite well-known research topic in Acoustics and Signal Processing, but considering its implication in Robotics, it is not as easy as expected to port all the already developments inside a robot. The robotic context exhibit original constraints like embeddability, real-time, reveberations, ego-noise, etc.\nTwo main paradigms are currently exploited in Robotics:\n on the one hand, array processing approaches exploit microphones array to exploit redundant audio information to perform sound source localization, source separation, source recognition in a very efficient way. Recent developments definitely show that this is the way to go to develop an efficient audio system in Robotics; on the other hand, binaural approaches try to somewhat mimic the human auditory system, at least from an external point of view (two ears, generally with two external ears). Using only two ears in a Robotics context is still a very challenging task. But while one could question the choice to restrict ourself to only two ears, this is also a unique opportunity to test auditory models of human audition, and to stress the importance of action in the hearing process.  Indeed, hearing is rarely a purely static task. For instance, one often makes small head movements to disambiguate sound location, or better sound recognition. This is specifically what I have been dealing with, i.e. active binaural audition. On this topic, I have mainly proposed contributions on:\n the characterization of binaural cues used for sound localization and source recognition in realistic conditions, the specific sound localization problem, the use of the binaural movement to better sound localization, and the building of multimodal representation of unknown environments through head movements.  ","date":1577895614,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579727422,"objectID":"82fe4e7efb01c8660931e5d56ecf63f2","permalink":"https://my.sylar.org/project/robot_audition/","publishdate":"2020-01-01T17:20:14+01:00","relpermalink":"/project/robot_audition/","section":"project","summary":"where we deal with how to understand an audio scene","tags":[],"title":"Robot audition","type":"project"},{"authors":["Benjamin Cohen-Lhyver","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"c148b22b1fb5154bcc061fb0e4757924","permalink":"https://my.sylar.org/publication/2020b_audition_as_a_trigger/","publishdate":"2020-01-03T18:05:10+01:00","relpermalink":"/publication/2020b_audition_as_a_trigger/","section":"publication","summary":"In multimodal realistic environments, audition and vision are the prominent two sensory modalities that work together to provide humans with a best possible perceptual understanding of the environment. Yet, when designing artificial binaural systems, this collaboration is often not honored. Instead, substantial effort is made to construct best performing purely auditory-scene-analysis systems, sometimes with goals and ambitions that reach beyond human capabilities. It is often not considered that, what enables us to perform so well in complex environments, is the ability of: (i) using more than one source of information, for instance, visual in addition to auditory one and, (ii) making assumptions about the objects to be perceived on the basis of a priori knowledge. In fact, the human capability of inferring information from one modality to another one helps substantially to efficiently analyze the complex environments that humans face everyday. Along this line of thinking, this chapter addresses the effects of attention reorientation triggered by audition. Accordingly, it discusses mechanisms that lead to appropriate motor reactions, such as head movements for putting our visual sensors toward an audiovisual object of interest. After presenting some of the neuronal foundations of multimodal integration and motor reactions linked to auditory-visual perception, some ideas and issues from the field of a robotics are tackled. This is accomplished by referring to computational modeling. Thereby some biological bases are discussed as underlie active multimodal perception, and it is demonstrated how these can be taken into account when designing artificial agents endowed with human-like perception.","tags":[],"title":"Audition as a Trigger for Head Movements","type":"publication"},{"authors":["Valentin Marcel","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"d3e837983ba81c8fc3e291defea25ba4","permalink":"https://my.sylar.org/publication/2020j_where_do_i_move/","publishdate":"2020-01-01T21:47:45+01:00","relpermalink":"/publication/2020j_where_do_i_move/","section":"publication","summary":"This paper deals with the perception of mobile robotic systems within the framework of interactive perception, and inspired by the sensorimotor contingencies (SMC) theory. These approaches state that perception arises from active exploration of an environment. In the SMC theory, it is postulated that information about the structure of space could be recovered from a quasi-uninterpreted sensorimotor flow. In a recent article, the authors have provided a mathematical framework for the construction of a sensorimotor representation of the interaction between the sensors and the body of a naive agent, provided that the sensory inputs come from the agent's own body. An extension of these results, with stimulations coming from an unknown changing environment, is proposed in this paper. More precisely it is demonstrated that, through repeated explorations of its motor configurations, the perceived sensory invariants can be exploited to build a topologically accurate internal representation of the relative poses of the agent's sensors in the physical world. Precise theoretical considerations are provided as well as an experimental framework assessed in simulated but challenging environments.","tags":[],"title":"Where do I move my sensors? Emergence of a topological representation of sensors poses from the sensorimotor flow","type":"publication"},{"authors":["Sylvain Argentieri"],"categories":[],"content":"","date":1544083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"06980f7a8557ab594c7b699ff4b72c79","permalink":"https://my.sylar.org/publication/2018_hdr/","publishdate":"2020-01-03T17:54:34+01:00","relpermalink":"/publication/2018_hdr/","section":"publication","summary":"(This dissertation is written in French). Being able to perceive and analyse an auditory scene has been identified about 20 years ago as one of the seven challenges faced by artificial intelligence in Robotics. It is today a scientific topic on its own, dealt with by multiple scientific Communities (Signal Processing, Acoustics, Robotics). While the Robot Audition community has been mainly focused on microphone array based approaches, exploiting only two microphones in a binaural setup is still a challenging task. The work presented in the first part of this dissertation deals with binaural audition, and is dedicated to sound source localization and active multimodal scene analysis in realistic robotics conditions involving noise and reverberations. The movement of the robotic plateform plays a fundamental role in these works: while causing changes in acoustic conditions, the robot action can also been exploited by closing the traditional perception/action loop to better the multimodal scene analysis. The second part of this dessertation is dedicated to a more formal approach to perception, where action can not be separated from perception anymore: perception is only possible by interacting on and with the environment. This interactive perception paradigm allows to study how a naive system is able to build by itself a representation of its interaction with its environmenent by discovering invariant structures inside its own sensorimotor flow. This formal approach could allow the robot to incrementally experience the notion of space, shared by the system and objects in the environment. Such a fundamental problematic has not been addressed specifically inside the audio modality, and aims at proposing a new sensorimotor framework to better understand the perception process that could allow Robotics system to gain in Autonomy.","tags":[],"title":"Un (petit) pas vers la perception interactive","type":"publication"},{"authors":["Valentin Marcel","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1536566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"d1f6701016afeeb6de5defe316c1e4f1","permalink":"https://my.sylar.org/publication/2018w_where_do_i_move/","publishdate":"2020-01-03T18:03:06+01:00","relpermalink":"/publication/2018w_where_do_i_move/","section":"publication","summary":"In autonomous robotics the question of the representation of the world is of crucial importance for the realization of complex tasks. However, building such a representation is often rooted on human-crafted a priori about the world. But as complexity increases this idea is not adapted anymore: fully autonomous agents in the real world require generalized representations. These must be built from experience and possibly with minimal external assumptions. This context is perfectly suited to the approach of sensorimotor perception, where the agent has to interpret the effects of naive actions on its inputs that come from exteroceptive and proprioceptive sensors. By exploiting basic sensory invariants, we show that it is possible to project the highly dimensional motor configurations into an internal representation of the sensors’ configuration space initially unknown to the agent. This allows the agent to build an internal model of the sensitive configurations.","tags":[],"title":"Where do I move my sensors? Emergence of an internal representation from the sensorimotor flow","type":"publication"},{"authors":["Benjamin Cohen-Lhyver","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1535616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"c6e0c2dc1a9dd796b59e6a9439ea134f","permalink":"https://my.sylar.org/publication/2018j_head_turning_modulation_system/","publishdate":"2020-01-03T17:58:49+01:00","relpermalink":"/publication/2018j_head_turning_modulation_system/","section":"publication","summary":"Over the last twenty years, a significant part of the research in exploratory robotics partially switches from looking for the most efficient way of exploring an unknown environment to finding what could motivate a robot to autonomously explore it. [...] The Head Turning Modulation model presented in this paper is composed of two modules providing a robot with two different forms of intrinsic motivations leading to triggering head movements towards audiovisual sources appearing in unknown environments. First, the Dynamic Weighting module implements a motivation by the concept of Congruence, a concept defined as an adaptive form of semantic saliency specific for each explored environment. Then, the Multimodal Fusion \u0026 Inference module implements a motivation by the reduction of Uncertainty through a self-supervised online learning algorithm that can autonomously determine local consistencies. [...] Results presented in this paper have been obtained in simulated environments as long as with a real robot in realistic experimental conditions.","tags":[],"title":"The Head Turning Modulation system: an active multimodal paradigm for intrinsically motivated exploration of unknown environments","type":"publication"},{"authors":["Elie Laurent Benaroya","Nicolas Obin","Marco Liuni","Axel Roebel","Wilson Raumel","Sylvain Argentieri"],"categories":[],"content":"","date":1527840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"d57a60068c9aca680d055b53c804a617","permalink":"https://my.sylar.org/publication/2018j_binaural_non_negative_tensor/","publishdate":"2020-01-03T17:56:52+01:00","relpermalink":"/publication/2018j_binaural_non_negative_tensor/","section":"publication","summary":"This paper presents non-negative factorization of audio signals for the binaural localization of multiple sound sources within realistic and unknown sound environments. Non-negative tensor factorization (NTF) provides a sparse representation of multichannel audio signals in time, frequency, and space that can be exploited in computational audio scene analysis and robot audition for the separation and localization of sound sources. In the proposed formulation, each sound source is represented by means of spectral dictionaries, temporal activation, and its distribution within each channel (here, left and right ears). This distribution, being dependent on the frequency, can be interpreted as an explicit estimation of the Head-Related Transfer Function (HRTF) of a binaural head which can then be converted into the estimated sound source position. Moreover, the semisupervised formulation of the non-negative factorization allows us to integrate prior knowledge about some sound sources of interest whose dictionaries can be learned in advance, whereas the remaining sources are considered as background sound, which remains unknown and is estimated on the fly. The proposed NTF-based sound source localization is applied here to binaural sound source localization of multiple speakers within realistic sound environments.","tags":[],"title":"Binaural Localization of Multiple Sound Sources by Non-Negative Tensor Factorization","type":"publication"},{"authors":["Valentin Marcel","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1496304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"5fa0dfaad2e712bb2eb3ecc0046a9120","permalink":"https://my.sylar.org/publication/2017j_building_sensorimotor_tactile_space/","publishdate":"2020-01-03T17:51:59+01:00","relpermalink":"/publication/2017j_building_sensorimotor_tactile_space/","section":"publication","summary":"A new approach for robotics perception, rooted in the sensorimotor paradigm, is proposed in this paper. Making systems able to autonomously adapt themselves to changes in their own body or in their environment is still a challenging question for many different scientific communities. Multiple works propose either sophisticated adaptive model-based or learning-based techniques as a solution. Recent contributions have shown that it is possible for an agent to discover the structure of its interaction with the environment or its own body via the so-called sensorimotor flow. The presented work is based on this idea, and a method for building an internal representation of sensorimotor interaction is proposed, which does not require any a priori knowledge or model. A careful mathematical formalization is outlined, together with simulations, demonstrating the effectiveness of the approach. Several cases are considered allowing for a general discussion. Moreover, plausibility of the internal sensorimotor representation is highlighted by showing that it is possible to consider motion planning directly from it.","tags":[],"title":"Building a Sensorimotor Representation of a Naive Agent’s Tactile Space","type":"publication"},{"authors":["Valentin Marcel","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1474268400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"06d7b7e33142c4a864820623869c8082","permalink":"https://my.sylar.org/publication/2016w_building_exploiting_sensorimotor_representation/","publishdate":"2020-01-03T17:49:21+01:00","relpermalink":"/publication/2016w_building_exploiting_sensorimotor_representation/","section":"publication","summary":"More and more researcher in artificial intelligence are concerned with perception of the environment. Ahead of consideration about objects or task spaces common in developmental robotics, this research is interested in the birth of the principle of space by a naive agent. It is only after having acquired this principle that it is possible to build the higher level paradigms such as the existence of objects or grasping tasks, etc. Indeed space existence is most of the time an a priori knowledge about the world which is brought by the engineer with the definition of models such as kinematics models or spatial state parameters. This work is based on the analysis of the so-called sensorimotor flow, particularly on the study of correlation and invariance in exteroceptive and proprioceptive signals, i.e. sensorimotor contingencies. Such contingencies carry fundamental structural information on the world. Poincaré suggested that information about dimension of the space in which the agent movements are embedded, such as the 3D euclidean space of translation or possibly more complex spaces, can be extracted from the study of sensorimotor manifold. Later, studies have been proposed by Philipona et. al then by Laflaquière et. al to extract this specific dimension. More recently, Laflaquière et. al have shown that it was also possible to obtain an internal representation of the agent’s movements in a simple environment by the construction of specific motor partitions. The approach is an extension of the work from Laflaquière et. al with a focus on self-interaction by the agent. Indeed, as pointed out by Frolov, self-interaction allows the agent not to make any prior hypothesis on environment stability as any sensation would be caused by the agent itself. From the use of sensory invariance and the construction of kernel sets, an internal, i.e. proprioceptive, representation of the self-touching interaction can be built. A first but incomplete solution have already been proposed which is completed in the present work. In the former, the internal representation is built to geometrically characterize the shape of the body, based on this, some contributions prove that it is also possible to use it as an internal representation of movements in space and as a basis for motor planning and particularly sensation reaching. This will allow a totally naive agent, with no knowledge on its structure or on the dimension of the space it is embedded in, to successfully predict self-interaction.","tags":[],"title":"Building and exploiting a sensorimotor representation of a naive agent self-interaction","type":"publication"},{"authors":["Benjamin Cohen-Lhyver","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1473058800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"6d4decf4193b1f17bd90a6f3c4a8dcf8","permalink":"https://my.sylar.org/publication/2016c_multimodal_fusion_and_inference_ica/","publishdate":"2020-01-03T17:45:08+01:00","relpermalink":"/publication/2016c_multimodal_fusion_and_inference_ica/","section":"publication","summary":"Hearing is a key modality on which several perceptual human processes rely on. Together with vision, these two modalities offer a 360 degrees wide, highly sensitive, quickly adaptive, and incredibly precise system of perception of the environment. In an exploratory robotics context, the concept of audiovisual objects is very relevant for a robot since it enables it to better understand its environment, and also to interact with it. However, how to face the cases when an object is out of sight, or when it does not emits sound, that is, the cases of missing information? The pro- posed Multimodal Fusion and Inference (MFI) system takes advantages of having (i) multimodal information and (ii) the ability to move in the environment, to implement a low-level attentional algorithm that enables a mobile robot to understand its environment in terms of audiovisual ob- jects. In the case of a missing modality, the proposed algorithm is able to infer the missing data thus providing to the robot full information to higher cognitive stages. The MFI system is based on an online and unsupervised learning algorithm using a modified self-organizing map. Furthermore, the MFI exploits the ability to turn the robot head towards objects, thus benefiting from active perception to reinforce autonomously what the system is actually learning. Results exhibits promising performances in closed-loop scenarios involving sound and image classifiers.","tags":[],"title":"Multimodal fusion and inference using binaural audition and vision","type":"publication"},{"authors":["Bruno Gas","Sylvain Argentieri"],"categories":[],"content":"","date":1454313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"b28915e68f5918a5c01ccc1cb5ad248d","permalink":"https://my.sylar.org/publication/2016j_intellectica/","publishdate":"2020-01-03T17:46:56+01:00","relpermalink":"/publication/2016j_intellectica/","section":"publication","summary":"A new approach to perception in Robotics, whose originality is to be redesigned in an exclusively sensorimotor framework is presented in this paper. Such an approach is receiving increasing interest within the research community from various disciplines, such as physics,  mathematics, cognitive sciences and computational neuroscience. In this context, Robotics might constitute a particularly well-suited experimental testbed and an ideal framework to hatch new  ideas about one of the most amazing −and yet very mysterious− faculties of animals and humans.   paper focuses first on the works by Poincaré on the perception of space geometry (and more specifically on its dimension) by sensorimotor means. Current works directly inspired from them  are also  highlighted. Then, other contributions trying to extend these ideas to the sensorimotor  representation of space are introduced. The question of the body representation, and the way the  motivation problematic can be formalized in this sensorimotor context, are both partially  addressed. This short introduction has beenmade with the hope to constitute a good opening to the  current understanding of the perception sensorimotor framework.","tags":[],"title":"Une brève introduction à la perception sensori-motrice en robotique","type":"publication"},{"authors":["Benjamin Cohen-Lhyver","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1449385200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"12d926149d534ba9421cb3a150a08656","permalink":"https://my.sylar.org/publication/2015c_modulating_turn_to_reflex/","publishdate":"2020-01-03T17:35:16+01:00","relpermalink":"/publication/2015c_modulating_turn_to_reflex/","section":"publication","summary":"This paper is focused on the triggering of Spontaneous Head Movements (SHM), i.e. head movements which are supposed to be used to get additional information on a specific area of the robot environment. For that purpose, a Dynamic Weighting model (DWmod) is formulated as a low-level attention algorithm which allows an exploratory robot to drive its attention toward important items. DWmod is primarily based on auditory information, possibly coupled with visual data. These audiovisual characterizations rely on classification experts whose outputs are used by DWmod to trigger a SHM. The attention mechanism modeled by DWmod is rooted in the notion of congruence and predictability of items, allowing the robot to dynamically create its own rules about what is important or not in the current scene. This behavior is especially relevant in exploration tasks and particularly in search \u0026 rescue scenarios, where the robot has to react quickly with potentially no knowledge at all about the current environment. Within the Two!Ears framework1, a three-layered architecture on a simulated robot is developed, and simulation results demonstrate how the proposed model outperform basic low-level auditory-based turn-to reflexes.","tags":[],"title":"Modulating the auditory turn-to reflex on the basis of multimodal feedback loops: The Dynamic Weighting model","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danès","Philippe Souères"],"categories":[],"content":"","date":1446361200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"1f8484f21cd9f14ca25090c5caecff88","permalink":"https://my.sylar.org/publication/2015j_survey_sound_source_localization/","publishdate":"2020-01-03T17:40:25+01:00","relpermalink":"/publication/2015j_survey_sound_source_localization/","section":"publication","summary":"This paper attempts to provide a state-of-the-art of sound source localization in robotics. Noticeably, this context raises original constraints—e.g. embeddability, real time, broadband environments, noise and reverberation—which are seldom simultaneously taken into account in acoustics or signal processing. A comprehensive review is proposed of recent robotics achievements, be they binaural or rooted in array processing techniques. The connections are highlighted with the underlying theory as well as with elements of physiology and neurology of human hearing.","tags":[],"title":"A survey on sound source localization in robotics: From binaural to array processing methods","type":"publication"},{"authors":["Valentin Marcel","Boris Garcia","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1443772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"a68e14d6d8bb09f4f42e4f483b6f6d4d","permalink":"https://my.sylar.org/publication/2015w_building_representation_body/","publishdate":"2020-01-03T17:42:20+01:00","relpermalink":"/publication/2015w_building_representation_body/","section":"publication","summary":"Making systems able to autonomously adapt them- selves to changes in their own body or in their environment is still a challenging task questioning a lot of different scientific communities. Many works propose either sophisticated adaptive model-based or learning-based techniques, as a solution. Most of them rely on the traditional perceive/decide/act framework, inspired by our human intuition about how we perceive the world. But recent contributions have shown that it is possible for an agent to discover the structure of its interaction with the environment or its own body via the so-called sensorimotor flow. This work is rooted in this paradigm, and a method for the building of an internal representation of the agent body is pro- posed. Importantly, it does not require any a priori knowledge nor model. A careful mathematical formalization is outlined, together with simulations demonstrating the effectiveness of the approach.","tags":[],"title":"Building the representation of an agent body from its sensorimotor invariants","type":"publication"},{"authors":["Alban Laflaquière","J. Kevin O’Regan","Sylvain Argentieri","Bruno Gas","Alexander V.Terekhov"],"categories":[],"content":"","date":1441094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"91d49df5531eb9dd5dc992401afb001a","permalink":"https://my.sylar.org/publication/2015j_learning_agents_spatial_configuration/","publishdate":"2020-01-03T17:38:05+01:00","relpermalink":"/publication/2015j_learning_agents_spatial_configuration/","section":"publication","summary":"The design of robotic systems is largely dictated by our purely human intuition about how we perceive the world. This intuition has been proven incorrect with regard to a number of critical issues, such as visual change blindness. In order to develop truly autonomous robots, we must step away from this intuition and let robotic agents develop their own way of perceiving. The robot should start from scratch and gradually develop perceptual notions, under no prior assumptions, exclusively by looking into its sensorimotor experience and identifying repetitive patterns and invariants. One of the most fundamental perceptual notions, space, cannot be an exception to this requirement. In this paper we look into the prerequisites for the emergence of simplified spatial notions on the basis of a robot’s sensorimotor flow. We show that the notion of space as environment-independent cannot be deduced solely from exteroceptive information, which is highly variable and is mainly determined by the contents of the environment. The environment-independent definition of space can be approached by looking into the functions that link the motor commands to changes in exteroceptive inputs. In a sufficiently rich environment, the kernels of these functions correspond uniquely to the spatial configuration of the agent’s exteroceptors. We simulate a redundant robotic arm with a retina installed at its end-point and show how this agent can learn the configuration space of its retina. The resulting manifold has the topology of the Cartesian product of a plane and a circle, and corresponds to the planar position and orientation of the retina.","tags":[],"title":"Learning agents spatial configuration from sensorimotor invariants","type":"publication"},{"authors":["Boris Garcia","Mathieu Bernard","Sylvain Argentieri","Bruno Gas"],"categories":[],"content":"","date":1410073200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"c1bb480926b8ddd60c4875fc88774e01","permalink":"https://my.sylar.org/publication/2014c_sensorimotor_learning_sound_localization/","publishdate":"2020-01-03T17:33:30+01:00","relpermalink":"/publication/2014c_sensorimotor_learning_sound_localization/","section":"publication","summary":"In the context of robot perception, a new set of methods for self-supervised sensorimotor learning has emerged lately. These methods try to extract robot and environment configuration information from a set of sensorimotor cues, with no use of any a priori knowledge. This paper is concerned with such methods, in the context of binaural robot audition. An incremental algorithm is proposed, relying on an auditory evoked behavior which allows a robot to orient its head toward a sound source. During the learning process, this evoked behavior is used in order to gather auditive and proprioceptive data before and after the head has moved to face the sound source. An auditorimotor map can then be constructed. Thereafter, when the source plays again near a set of previously learned configurations, the robot can use the auditorimotor map to infer a motor command that would make it face the source. In other terms, the robot has learned from past sensorimotor experiences how to localize a sound source in the space of its own motor azimuths. In the present article, we offer an experimental validation of the evoked behavior and put to the test an offline version of the algorithm. The auditory evoked behavior implementation being sufficiently accurate, our results show a good localization performance using the learned auditorimotor map.","tags":[],"title":"Sensorimotor Learning of Sound Localization for an Autonomous Robot","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1383462000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"20ede4e90d5424110d9abb50552f4a5d","permalink":"https://my.sylar.org/publication/2013c_learning_based_approach/","publishdate":"2020-01-03T17:26:19+01:00","relpermalink":"/publication/2013c_learning_based_approach/","section":"publication","summary":"Sound source localization is an important feature designed and implemented on robots and intelligent systems. Like other artificial audition tasks, it is constrained to multiple problems, notably sound reflections and noises. This paper presents a sound source azimuth estimation approach in reverberant environments. It exploits binaural signals in a humanoid robotic context. Interaural Time and Level Differences (ITD and ILD) are extracted on multiple frequency bands and combined with a neural network-based learning scheme. A cue filtering process is used to reduce the reverberations effects. The system has been evaluated with simulation and real data, in multiple aspects covering realistic robot operating conditions, and was proven satisfying and effective as will be shown and discussed in the paper.","tags":[],"title":"A learning-based approach to robust binaural sound localization","type":"publication"},{"authors":["Carlos Viña","Sylvain Argentieri","Marc Rébillat"],"categories":[],"content":"","date":1383462000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"373fd748ffb7b5026a273f4a09ed9895","permalink":"https://my.sylar.org/publication/2013c_spherical_cross_channel/","publishdate":"2020-01-03T17:28:32+01:00","relpermalink":"/publication/2013c_spherical_cross_channel/","section":"publication","summary":"This paper proposes a sound localization algorithm inspired by a cross-channel algorithm first studied by MacDonald et. al in 2008. The original algorithm assumes that the Head Related Transfer Functions (HRTFs) of the robotic head under study are precisely known, which is rarely the case in practice. Following the idea that any head is more or less spherical, the above assumption is relaxed by using HRTFs computed using a simple spherical head model with the same head radius as the robot head. In order to evaluate the proposed approach in realistic noisy conditions, an isotropic noise field is also computed and a precise definition of the Signal to Noise Ratio (SNR) in a binaural context is outlined. All these theoretical developments are finally assessed with simulated and experimental signals. Despite its simplicity, the proposed approach appears to be robust to noise and to provide reliable sound localization estimations in the frontal azimuthal plane.","tags":[],"title":"A spherical cross-channel algorithm for binaural sound localization","type":"publication"},{"authors":["Ivan Markovic","Alban Portello","Patrick Danès","Ivan Petrovic","Sylvain Argentieri"],"categories":[],"content":"","date":1383462000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"f65e5f42a94343e898d8c3efe59fede1","permalink":"https://my.sylar.org/publication/2013c_active_speaker_localization/","publishdate":"2020-01-03T17:31:07+01:00","relpermalink":"/publication/2013c_active_speaker_localization/","section":"publication","summary":"This paper deals with speaker localization in two dimensions from a mobile binaural head. A bootstrap particle filtering scheme is used to perform active localization, i.e. to infer source location by fusing the binaural perception with the sensor motor commands. It relies on an original pseudo-likelihood of the source azimuth which captures both the interaural level and phase differences. Since the pseudo-likelihood is discrete, it is fitted with a mixture of circular distributions in order to enhance its resolution. For the fitting task two mixtures are compared and evaluated, namely the mixture of von Mises and wrapped Cauchy distributions. Furthermore, a solution is presented for calculating the von Mises curvefitting with low uncertainty, since the direct implementation can quickly surpass double precision floating number representation. The performance of the filter is compared using both the raw and fitted pseudo-likelihoods on experiments recorded in an acoustically prepared room with ground-truth obtained from a motion capture system. The results show that the proposed algorithm successfully localizes the speaker with an advantage in the direction of the fitted von Mises mixture likelihood.","tags":[],"title":"Active speaker localization with circular likelihoods and bootstrap filtering","type":"publication"},{"authors":["Alban Portello","Patrick Danès","Sylvain Argentieri","Sylvain Pledel"],"categories":[],"content":"","date":1383462000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"996de08cf68d63d159b5fecbfbc6dc58","permalink":"https://my.sylar.org/publication/2013c_hrtf_base_source_azimuth/","publishdate":"2020-01-03T17:24:36+01:00","relpermalink":"/publication/2013c_hrtf_base_source_azimuth/","section":"publication","summary":"","tags":[],"title":"HRTF-based source azimuth estimation and activity detection from a binaural sensor","type":"publication"},{"authors":["ZeFeng Wang","Jean-Luc Zarader","Sylvain Argentieri","Karim Youssef"],"categories":[],"content":"","date":1378537200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"5ce22517ebbe1ed9ad2ca5628f58a272","permalink":"https://my.sylar.org/publication/2013b_decision_system_aircraft/","publishdate":"2020-01-03T17:21:53+01:00","relpermalink":"/publication/2013b_decision_system_aircraft/","section":"publication","summary":"Aircrafts are complex systems that require permanent and precise monitoring and troubleshooting. The automation of these tasks is thus of a high importance. This paper presents an intelligent decision system for faults diagnosis of aircrafts. The system relies on decision trees, being easier to interpret, quicker to learn than other data-driven methods, and able to work even with missing pieces of information. The used C4.5 algorithm automatically “learns” the best decision tree by performing a search through the set of possible trees according to the available training data. And Principal Component Analysis (PCA) is used to decrease the input data’s dimension. Compared to other methods, the proposed one is more advantageous and some presented evaluations demonstrate its abilities. High correct faults detection rates and low missed detection and false alarm rates are obtained. Such a decision system is highly useful for engineering consulting services, accumulating the knowledge for the operational rules of diagnosis, and the design of new aircrafts.","tags":[],"title":"A Decision System for Aircraft Faults Diagnosis Based on Classification Trees and PCA","type":"publication"},{"authors":["Sylvain Argentieri","Alban Portello","Mathieu Bernard","Patrick Danès","Bruno Gas"],"categories":[],"content":"","date":1378537200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"5f22c21b3e805c5371dfac7defbea68a","permalink":"https://my.sylar.org/publication/2013b_binaural_system_robotics/","publishdate":"2020-01-03T17:19:05+01:00","relpermalink":"/publication/2013b_binaural_system_robotics/","section":"publication","summary":"Audition is often described by physiologists as the most important sense in humans, due to its essential role in communication and socialization. But quite surprisingly, the interest of this modality for robotics arose only in the 2000s, brought to evidence by cognitive robotics and Human–robot interaction. Since then, numerous contributions have been proposed to the field of robot audition, ranging from sound localization to scene analysis. Binaural approaches were investigated first, then became forsaken due to mixed results. Nevertheless, the last years have witnessed a renewal of interest in binaural active audition, that is, in the opportunities and challenges opened by the coupling of binaural sensing and robot motion. This chapter proposes a comprehensive state of the art of binaural approaches to robot audition. Though the literature on binaural audition and, more generally, on acoustics and signal processing, is a fundamental source of knowledge, the tasks, constraints, and environments of robotics raise original issues. These are reviewed, prior to the most prominent contributions, platforms and projects. Two lines of research in binaural active audition, conducted by the current authors, are then outlined, one of which is tightly connected to psychology of perception.","tags":[],"title":"Binaural Systems in Robotics","type":"publication"},{"authors":["ZeFeng Wang","Jean-Luc Zarader","Sylvain Argentieri"],"categories":[],"content":"","date":1354690800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"9ee15acc91d250b202439bb2b8893761","permalink":"https://my.sylar.org/publication/2012c_fault_diagnosis_system_gaussian/","publishdate":"2020-01-03T13:31:39+01:00","relpermalink":"/publication/2012c_fault_diagnosis_system_gaussian/","section":"publication","summary":"The goal of this work is to build an effective and practical system to diagnose and prognose faults of complex systems, like aircraft, satellite and so on. In this paper, a machine-learning method Gaussian Mixture Models (GMMs) is used to automatically detect, isolate, and even forecast the faults, while keeping the reliability and safety of complex system. Each dysfunctional model is completed by GMMs during machine learning, which constitutes the diagnosis system to distinguish and troubleshooting the faults. On the other side, principal component analysis (PCA) is combined with the system to improve the efficiency of GMMs, which can effectively compress the high dimensional data. Except for that, GMMs helps the system to achieve the visualization of dysfunctional models. With this visualization, the prognosis system can surveil the evolution of data and estimate their tendency, which is important to forecast the next condition of the complex system. The diagnosis and prognosis system proposed in this paper has been fully tested by using actual experimental data of aircraft X, which is supplied by Dassault Aviation.","tags":[],"title":"A novel aircraft fault diagnosis and prognosis system based on Gaussian Mixture Models","type":"publication"},{"authors":["Alban Laflaquière","Sylvain Argentieri","Olivia Breysse","Stéphane Genet","Bruno Gas"],"categories":[],"content":"","date":1349593200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"ee42234ae46b01296735bd3cb5992bfe","permalink":"https://my.sylar.org/publication/2012c_non_linear_approach/","publishdate":"2020-01-03T13:38:32+01:00","relpermalink":"/publication/2012c_non_linear_approach/","section":"publication","summary":"Developmental Robotics offers a new approach to numerous AI features that are often taken as granted. Traditionally, perception is supposed to be an inherent capacity of the agent. Moreover, it largely relies on models built by the system's designer. A new approach is to consider perception as an experimentally acquired ability that is learned exclusively through the analysis of the agent's sensorimotor flow. Previous works, based on H.Poincaré's intuitions and the sensorimotor contingencies theory, allow a simulated agent to extract the dimension of geometrical space in which it is immersed without any a priori knowledge. Those results are limited to infinitesimal movement's amplitude of the system. In this paper, a non-linear dimension estimation method is proposed to push back this limitation.","tags":[],"title":"A non-linear approach to space dimension perception by a naive agent","type":"publication"},{"authors":["Alban Portello","Patrick Danès","Sylvain Argentieri"],"categories":[],"content":"","date":1349593200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"5c4e2986056c1d756504093e4caca2c4","permalink":"https://my.sylar.org/publication/2012c_active_binaural_localization/","publishdate":"2020-01-03T13:26:45+01:00","relpermalink":"/publication/2012c_active_binaural_localization/","section":"publication","summary":"This paper takes place within the field of active sound source localization in a binaural context. A stochastic filtering strategy is presented for the localization of a still or moving source from a moving binaural sensor. The proposed method accounts for the source intermittence as well as for false measurements induced by the non-stationarity of the emitted signal. Its effectiveness is showed on experimental results.","tags":[],"title":"Active binaural localization of intermittent moving sources in the presence of false measurements","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1349593200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"7efc7c4881cedf719f355acdcb7de663","permalink":"https://my.sylar.org/publication/2012c_towards_systematic/","publishdate":"2020-01-03T13:43:15+01:00","relpermalink":"/publication/2012c_towards_systematic/","section":"publication","summary":"Sound source localization is a need for robotic systems interacting with acoustically-active environments. In this domain, numerous binaural localization studies have been conducted within the last few decades. This paper provides an overview of a number of binaural localization cue extraction techniques. These are carefully addressed and applied on a simulated binaural database. Cues are evaluated in azimuth estimation and their discriminatory effectiveness is studied as a function of the reverberation time with statistical data analysis techniques. Results show that big differences exist between the discriminatory abilities of multiple types of cue extraction methods. Thus a careful cue selection must be performed before establishing a sound localization system.","tags":[],"title":"Towards a systematic study of binaural cues","type":"publication"},{"authors":["ZeFeng Wang","Jean-Luc Zarader","Sylvain Argentieri"],"categories":[],"content":"","date":1348383600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"c462d4c2039a746a68955c40917b8823","permalink":"https://my.sylar.org/publication/2012c_fault_diagnosis_system_svm/","publishdate":"2020-01-03T13:34:49+01:00","relpermalink":"/publication/2012c_fault_diagnosis_system_svm/","section":"publication","summary":"The goal of this work is to build a novel diagnostic and prognostic system of aircraft, especially for system of aircraft's engines. Different from classical diagnostic and prognostic system, like Condition-Based Maintenance (CBM) / Prognostic Health Management (PHM), this system can be used on aircraft not only off-line for maintenance, but also at on-line during its flight mission. Machine learning of the system will be done with more powerful computer at Aircraft Ground Center or Maintenance Center. According to the different situations requirement and different equipment's conditions, two monitoring terminals are built: one is on operation at the aircraft on-line, which only needs to make 2 judgments of the health of aircraft - normal (contains the small faults which fault tolerant system can resolve) and dangerous (-back to airport) for pilot; another one is for the maintenance office, which needs detailed diagnosis results and to forecast the aircraft health. In comparison with some other methods, Support Vector Machines (SVM) is more convenient and stable. Unlike expect system or others methods, it can easily add new faults and new rules into database. In addition, with Principal Component Analysis (PCA), it can also make a visualization of evaluation of flux data with haut dimension and of their boundary, which is used to realize prognosis and useful for engineers to study faults. This system should not be a black box. Indeed, it is designed to illuminate engineering consulting services, and to accumulate the knowledge for re-engineering purposes (including diagnosis operational rules) and the design of new aircrafts. The system has been fully tested by using actual experimental data from Dassault Aviation.","tags":[],"title":"A novel aircraft engine fault diagnostic and prognostic system based on SVM","type":"publication"},{"authors":["ZeFeng Wang","Jean-Luc Zarader","Sylvain Argentieri"],"categories":[],"content":"","date":1342335600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"a61e9dab6077a6a00b62de2dad37b1db","permalink":"https://my.sylar.org/publication/2012c_fault_diagnosis_system/","publishdate":"2020-01-03T13:36:32+01:00","relpermalink":"/publication/2012c_fault_diagnosis_system/","section":"publication","summary":"With the development of aerotechnics and requirements of aircraft performance, the system of aircraft becomes multi-functional and more complex. Such a complex system, it is difficult to fault diagnosis by traditional methods, which are performed by expertise, by observing how the system works (generally through unit tests on each component of the complex system). It costs more time and more human resources. Through modern aircrafts generally have a good robust performance and the fault tolerant system can neutralize some faults, it arouses more hidden danger. The small symptoms of faults are covered and it becomes more difficult to detect them by maintenance staff. If they can not be found in time, maybe it leads to some terrible accidents. Consequently, aircraft needs to embed a fault diagnosis system to achieve self-diagnosis and the system needs to be intelligent to analysis different condition of aircraft, give an alarm to pilot in necessary and send a report to engineer and maintenance staff.","tags":[],"title":"A novel fault diagnosis system for aircraft based on adaboost and five subsystems with different pattern recognition methods","type":"publication"},{"authors":["Zefeng Wang","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1341990000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"2667b6f87c9fdec6618d24accc701d83","permalink":"https://my.sylar.org/publication/2012c_aircraft_fault_diagnosis/","publishdate":"2020-01-03T13:28:20+01:00","relpermalink":"/publication/2012c_aircraft_fault_diagnosis/","section":"publication","summary":"The goal of this work is to build an aircraft fault diagnosis and decision system, which uses data-driven methods to automatically detect and isolate faults in the aircraft, while keeping its reliability and safety. As a fundamental specification, this fault diagnosis system should not be a black box, the condition monitoring and the results of comprehensive diagnosis shall be illuminated to engineering consulting services, and it can help engineers to accumulate the knowledge for reengineering purposes (including diagnosis operational rules) and improve the design of new aircraft. In comparison with some methods, Artificial Neural Networks (ANN) has been shown to be more advantageous and is currently used in fault diagnosis system. For example, it hasn't any problem of conflict of new rules, which is a big problem in Expert System while adding new fault. In this work, ANN is improved. Its speed of learning and the iteration times can be self-corrected or mutated. Moreover, neural network can be combined with other optimization methods, like genetic methods, to achieve a better performance. Furthermore, according to the different types of sensors, certain sub-networks are built to assist the principal network or replace it in some anomaly condition. A decision system treats the results of all the networks and comes to a conclusion, which will be sent to pilot, airport command center (ACC), or fault tolerant system.","tags":[],"title":"Aircraft fault diagnosis and decision system based on improved artificial neural networks","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1332658800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"016f8d178e5646e24381ad10eeffa79e","permalink":"https://my.sylar.org/publication/2012c_auditive_cues_and_vision/","publishdate":"2020-01-03T13:30:07+01:00","relpermalink":"/publication/2012c_auditive_cues_and_vision/","section":"publication","summary":"A fundamental task for a robotic audition system is sound source localization. This paper addresses the localization problem in a robotic humanoid context, providing a novel learning algorithm that uses binaural cues to determine the sound source's position. Sound signals are extracted from a humanoid robot's ears. Binaural cues are then computed to provide inputs for a neural network. The neural network uses pixel coordinates of a sound source in a camera image as outputs. This learning approach provides good localization performances as it reaches very small errors for azimuth and elevation angles estimates.","tags":[],"title":"A binaural sound source localization method using auditive cues and vision","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1323241200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"4e24376a9536ee28f2b9023b12e7fd00","permalink":"https://my.sylar.org/publication/2011c_multimodal_sound_localization/","publishdate":"2020-01-03T09:46:10+01:00","relpermalink":"/publication/2011c_multimodal_sound_localization/","section":"publication","summary":"This paper deals with sound source localization in a humanoid robotics context. Classical binaural localization algorithms often rely on the following process: first, binaural cues are extracted from the left and right microphone/ear signals; next, a model is exploited to infer the possible localization of the sound source. Such a method thus requires an accurate modeling of the head acoustic shadowing, or precise Head-Related Transfer Function measurements. In order to avoid these last complicated steps, we propose in this paper an original multimodal sound source localization method. The relationship between binaural auditory cues and the position of the sound source to be located in an image is learned by a partially-connected neural network. This approach has a higher resolution and is less complex than state-of-the art techniques. Simulations and experimental results are shown, demonstrating the effectiveness of the proposed method. A very accurate azimuth estimation is provided, while elevation requires additive cues to be more efficiently approximated.","tags":[],"title":"Multimodal sound localization for humanoid robots based on visio-auditive learning","type":"publication"},{"authors":["Alban Portello","Patrick Danès","Sylvain Argentieri"],"categories":[],"content":"","date":1316934000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"a72809777ee804cdbc9881954d3ffef6","permalink":"https://my.sylar.org/publication/2011c_acoustics_model_kalman/","publishdate":"2020-01-03T09:42:03+01:00","relpermalink":"/publication/2011c_acoustics_model_kalman/","section":"publication","summary":"This paper deals with binaural sound localization. An active strategy is proposed, relying on a precise model of the dynamic changes induced by motion on the auditive perception. The proposed framework allows motions of both the sound source and the sensor. The resulting stochastic discrete-time model is then exploited together with Unscented Kalman filtering to provide range and azimuth estimation. Simulations and experiments show the effectiveness of the method.","tags":[],"title":"Acoustic models and Kalman filtering strategies for active binaural sound localization","type":"publication"},{"authors":["Karim Youssef","Bastien Breteau","Sylvain Argentieri","Jean-Luc Zarader","Zefeng Wang"],"categories":[],"content":"","date":1303887600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"b5f6cc6522f8989383dcbe74b65d0ffa","permalink":"https://my.sylar.org/publication/2011c_approaches_speaker_reco/","publishdate":"2020-01-03T09:44:30+01:00","relpermalink":"/publication/2011c_approaches_speaker_reco/","section":"publication","summary":"This paper presents two methods of Automatic Speaker Recognition (ASkR). ASkR has been largely studied in the last decades, but in most cases in mono-microphone or microphone array contexts. Our systems are placed in a binaural humanoid context where the signals captured by both ears of a humanoid robot will be exploited to perform the ASkR. Both methods use Mel-Frequency Cepstral Coding (MFCC), but one performs the classification with Predictive Neural Networks (PNN) and the other performs it with Gaussian Mixture Models (GMM). Tests are made on a database simulating the functioning of the human ears. They study the influence of noise, reverberations and speaker spatial position on the recognition rate.","tags":[],"title":"Approaches for Automatic Speaker Recognition in a Binaural Humanoid Context","type":"publication"},{"authors":["Bastien Breteau","Sylvain Argentieri","Jean-Luc Zarader","Zefeng Wang","Karim Youssef"],"categories":[],"content":"","date":1292313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"7e527f39c736ce3592dc176e38c802fe","permalink":"https://my.sylar.org/publication/2010c_binaural_speaker_recognition2/","publishdate":"2020-01-02T16:02:51+01:00","relpermalink":"/publication/2010c_binaural_speaker_recognition2/","section":"publication","summary":"This paper deals with Automatic Speaker Recognition in a binaural context. Such a problematic, not so widely dealt with within the speech processing community, can have potential applications in humanoid robots where speech can be used as the most natural interface between humans and robots. The proposed recognition system is based on parallel Predictive Neural Networks exploiting MFCCs (Mel Frequency Cepstral Coefficients) to discriminate multiple talkers. Because of the binaural nature of the system, the sensitivity of the proposed algorithm to the speaker spatial position during the learning step is carefully studied. The influence of noise and reverberation on the recognition rate is also reviewed. Finally, preliminary experimental results based on the recorded signals from a binaural dummy head are presented.","tags":[],"title":"Binaural Speaker Recognition for humanoid robots","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1291708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"66602e578390154b94791839d85a7c79","permalink":"https://my.sylar.org/publication/2010c_binaural_speaker_recognition/","publishdate":"2020-01-02T16:00:37+01:00","relpermalink":"/publication/2010c_binaural_speaker_recognition/","section":"publication","summary":"In this paper, an original study of a binaural speaker identification system is presented. The state of the art shows that, contrarily to monaural and multi-microphone approaches, binaural systems are not so much studied in the specific task of automatic speaker recognition. Indeed, these systems are mostly used for speech recognition, or speaker localization. This study will focus on the benefits of the binaural context in comparison with monaural techniques. It demonstrates the interest of the binaural systems typically used in humanoid robotics. The system is first tested with monaural signals, and then with a binaural sensor, in many signal to noise ratios, speech durations and speaker directions. Up to 11 percent of improvement in recognition ratios of 23 ms frames can be obtained. The used database is a set of audio tracks recorded for 10 speakers, and filtered by HRTFs to obtain binaural signals in the directions of interest, for the binaural training and testing steps. This way, we study the sensitivity of the system to the speaker's location in an environment where a maximum of 10 speakers is present.","tags":[],"title":"Binaural speaker recognition for humanoid robots","type":"publication"},{"authors":["Karim Youssef","Sylvain Argentieri","Jean-Luc Zarader"],"categories":[],"content":"","date":1291622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"ed51362f4aa85b327c8e2b859703de3f","permalink":"https://my.sylar.org/publication/2010c_monaural_binaural_speaker_recognition/","publishdate":"2020-01-02T16:04:53+01:00","relpermalink":"/publication/2010c_monaural_binaural_speaker_recognition/","section":"publication","summary":"This paper addresses speaker recognition in a binaural context. Such an auditory sensor is naturally well suited to humanoid robotics as it only requires two microphones embedded in artificial ears. But the state of the art shows that, contrary to monaural and multi-microphone approaches, binaural systems are not so much studied in the specific task of automatic speaker recognition. Indeed, these sensors are mostly used for speech recognition, or speaker localization. This study will then focus on the benefits of the binaural context in comparison with monaural techniques. The proposed approach is first evaluated in simulation through a HRTF database reproducing the head shadowing effect and with a 10-speakers database. Next, the method is assessed with an experimental binaural 15-speakers database recorded in our own almost-anechoic room for various SNR conditions. Results show that the speaker positions during the learning step of the proposed approach strongly influence the recognition rates.","tags":[],"title":"From monaural to binaural speaker recognition for humanoid robots","type":"publication"},{"authors":["Alban Laflaquière","Sylvain Argentieri","Bruno Gas","Eduardo Castillo-Castenada"],"categories":[],"content":"","date":1287385200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"9e0a4cdc05edfc10fc734ca5bcf8d43a","permalink":"https://my.sylar.org/publication/2010c_space_dimension_perception/","publishdate":"2020-01-02T16:07:22+01:00","relpermalink":"/publication/2010c_space_dimension_perception/","section":"publication","summary":"Perception and action are fundamental tasks for autonomous robots. Traditionnally, they rely on theoretical models built by the system's designer. But, is a naive agent able to learn by itself the structure of its interaction with the environment without any a priori information? This knowledge should be extracted through the analysis of the only information it has access to: its high-dimensional sensorimotor flow. Recent works, based on the sensorimotor contingencies theory, allow a simulated agent to extract the geometrical space dimensionality without any model of itself nor of the environment. In this paper, these results are validated using a more sophisticated auditive modality. The question of multimodality fusion is then addressed by fitting up the agent with vision. Finally, preliminary experimental results on a real robotic platform are presented.","tags":[],"title":"Space dimension perception from the multimodal sensorimotor flow of a naive robotic agent","type":"publication"},{"authors":["Julien Bonnal","Sylvain Argentieri","Patrick Danès","Jérome Manhès","Philippe Souères","Marc Renaud"],"categories":[],"content":"","date":1275375600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"f58dbfbf92981e3b1ca7f282326802c9","permalink":"https://my.sylar.org/publication/2010j_the_ear_project/","publishdate":"2020-01-03T09:39:39+01:00","relpermalink":"/publication/2010j_the_ear_project/","section":"publication","summary":"Audition is often considered as the most important sense in humans, because of its fundamental role in learning, language and communication. However, its use in robotics is fairly recent in comparison to other exteroceptive sensing. Nevertheless, its complementarity to vision and its potentialities for Human-Robot Interaction have been widely acknowledged. Besides binaural approaches, array processing constitutes a relevant way to endow robots with audition. The idea is to exploit the redundancy of the data sensed by an array of microphones so as to design robust and efficient functions. Most contributions in robotics have been rooted in the Computational Auditory Scene Analysis (CASA) framework. This in turn has given rise to unexpected original requirements. To cite few, any solution must be easily embeddable (geometry and energy consumption), perform in real time, handle wideband signals (e.g. the human voice), and cope with noise and reverberations. In this context, LAAS-CNRS has developed an integrated auditory sensor named EAR (“Embedded Au- dition for Robotics”), on the basis of a linear array of eight microphones, a fully programmable acquisition board, a FPGA processing unit, and USB communication. This paper describes its design and its exploitation in a robotics experiment.","tags":[],"title":"The EAR Project","type":"publication"},{"authors":["Julien Bonnal","Sylvain Argentieri","Patrick Danés","Jérôme Manhès"],"categories":[],"content":"","date":1255161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"e0b08bc1e96d219cadc35b899df21f1f","permalink":"https://my.sylar.org/publication/2009c_speaker_localization_ear/","publishdate":"2020-01-02T15:58:28+01:00","relpermalink":"/publication/2009c_speaker_localization_ear/","section":"publication","summary":"This paper presents the embedded audition for robotics (EAR) project internally developed at LAAS and its application to speaker localization and extraction. Hardware and software issues are first thoroughly depicted, concerning the development of an auditory sensor based on an array of microphones, a homemade dedicated acquisition chain and a FPGA based processing board. Then, the EAR sensor is assessed against various scenarios, in real noisy robotics environments. Localization results are presented when a speaker emits an utterance in the presence of a disturbing source. These validate the underlying theory and suggest further theoretical and experimental developments.","tags":[],"title":"Speaker localization and speech extraction with the EAR sensor","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés"],"categories":[],"content":"","date":1193644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"79cf0f52b2e5ad08fb7cd0782b399f38","permalink":"https://my.sylar.org/publication/2007c_broadband_variation_music/","publishdate":"2020-01-02T15:53:58+01:00","relpermalink":"/publication/2007c_broadband_variation_music/","section":"publication","summary":"The MUSIC algorithm (multiple signal classification) is a well-known high-resolution method to sound source localization. However, as it is essentially narrowband, several extensions can be envisaged when dealing with broadband sources like human voice. This paper presents such extensions and proposes a comparative study w.r.t. specific robotics constraints. An online beamspace MUSIC method, together with a recently developed beamforming scheme, are shown to constitute a mathematically sound and potentially efficient solution.","tags":[],"title":"Broadband variations of the MUSIC high-resolution method for Sound Source Localization in Robotics","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés"],"categories":[],"content":"","date":1188806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"18aa7f53481624693f329fbe0cc77961","permalink":"https://my.sylar.org/publication/2007c_convex_optimization_robotics/","publishdate":"2020-01-02T15:56:09+01:00","relpermalink":"/publication/2007c_convex_optimization_robotics/","section":"publication","summary":"This paper deals with sound source localization in mobile robotics. This context opens new areas of research as it involves some specific constraints such as real time perfor- mance or embeddability. Quite often, broadband beamform- ing techniques are sought for, exploiting small-sized micro- phone arrays. A new approach to the design of broadband nearfield or farfield beamformers is first described, based on modal analysis and convex optimization. Original consid- erations related to the involvement of the theoretical beam- pattern into the real integrated acoustic sensor are then pre- sented, which lead to alleviate some constraints during the optimization process and enable the use of smaller arrays. The whole method is illustrated on an example.","tags":[],"title":"Convex Optimization and Modal Analysis for Beamforming in Robotics : Theoretical and Implementation Issues","type":"publication"},{"authors":["Sylvain Argentieri"],"categories":[],"content":"","date":1165564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"0c60971f57bb54800584edbc12aaeaaa","permalink":"https://my.sylar.org/publication/2006_phd/","publishdate":"2020-01-02T15:48:39+01:00","relpermalink":"/publication/2006_phd/","section":"publication","summary":"(This dissertation is written in French). The auditory system provides the human with many informations on its acoustic environment. For instance, we are able to precisely localize the origin of a sound and interpret its meaning, so that it would be very difficult to do without these auditory cues in our dynamic and evolving world. Yet, mobile robotics has seldom integrated this auditory modality despite its compulsoriness in order to complete the informations delivered by other exteroceptive sensors such as cameras, laser range-finders or ultrasonic detectors. This doctoral thesis deals with the design of an artificial auditory system for sound source localization, composed of an array of 8 omnidirectional microphones and an aquisition/processing board. This problematics has already been studied in Signal Processing and Acoustics. However, the unusual embeddability and real-time constraints imposed by the robotics context limit the applicability of such methods to wideband signals such as human voice. After a thorough bibiliographical study of the approaches to localization proposed in Robotics, the synthesis of frequency-invariant beamformers is envisaged. An original solution is proposed, based on convex optimization and relying on the modal representation of antenna directivity patterns. Compared to classical methods, its resolution at low frequencies is enhanced, be the source in the farfield or in the nearfield, despite the small size of the array. These optimized beamformers are then exploited so as to compute an acoustic power map of the environment. The localization turns to be more precise than with conventional approaches, and can process wideband signals in the frequency range 400Hz-3kHz. Last, a recent beamspace extension of the high-resolution MUSIC method is assessed, which could cope with the robotics constraints.","tags":[],"title":"Conception d'un capteur sonore pour la localisation de source en robotique mobile","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés","Philippe Souères"],"categories":[],"content":"","date":1160380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"2c598343125e801e8ed14e2eb0280a34","permalink":"https://my.sylar.org/publication/2006c_modal_analysis/","publishdate":"2020-01-02T15:51:23+01:00","relpermalink":"/publication/2006c_modal_analysis/","section":"publication","summary":"This paper describes a broadband beampattern synthesis method for sound source localization in the nearfield or in the farfield of a mobile robot, with a small-size linear array. The method is based on the theory of modal analysis and involves an original convex optimization procedure which benefits from the Parseval relation. The optimized beampattern is obtained by numerically minimizing the worst-case error between the modal coefficients of the array response and those of the reference beampattern, up to a finite rank of the series expansion, over a frequency grid. Simulations illustrate the analytical development.","tags":[],"title":"Modal Analysis Based Beamforming for Nearfield or Farfield Speaker Localization in Robotics","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés","Philippe Souères"],"categories":[],"content":"","date":1125648000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577914833,"objectID":"36ab5e765d18d786075041717d52b382","permalink":"https://my.sylar.org/publication/2005c_conception_systeme_localisation/","publishdate":"2020-01-01T17:48:22+01:00","relpermalink":"/publication/2005c_conception_systeme_localisation/","section":"publication","summary":"The work presented in this paper comes as a part of a project which aims at developing an auditory sytem for a mobile robot in order to localize a speaker. The proposed localization method is based on a convex optimization solution to wideband beamforming. A precise description of the optimization procedure together with the acquisition chain of the experimental testbed is given in order to bridge the gap between theory and practical implementation. Simulation results and comparisons with classical beamforming techniques are also provided.","tags":[],"title":"Conception d'un système de localisation de source sonore large bande par formation de voie pour des applications robotiques.","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés","Philippe Souères","P. Lacroix"],"categories":[],"content":"","date":1122969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577914833,"objectID":"d96abf534c2d6bd19ebcb8d59c8dbd01","permalink":"https://my.sylar.org/publication/2005c_experimental_testbed/","publishdate":"2020-01-01T21:33:22+01:00","relpermalink":"/publication/2005c_experimental_testbed/","section":"publication","summary":"This paper addresses the problem of practically implementing an original sound source localization strategy for mobile robots applications. The proposed method is based on a convex optimization solution to beamforming. It allows the sensing of signals within a direction of arrival and frequency domain of interest while rejecting other data. A precise description of the acquisition chain is proposed and a careful mathematical modeling is given in order to bridge the gap between theory and practical implementation. Simulation results and comparisons with classical filter-sum beamformer techniques are provided at the end of the paper to illustrate the performance of the sensor.","tags":[],"title":"An experimental testbed for sound source localization with mobile robots using optimized wideband beamformers","type":"publication"},{"authors":["Sylvain Argentieri","Patrick Danés","Philippe Souères"],"categories":[],"content":"","date":1113811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578071859,"objectID":"7725f2fa6cab9203a28c73c58d17b2c4","permalink":"https://my.sylar.org/publication/2005c_prototyping_filtersum_beamforming/","publishdate":"2020-01-02T15:43:06+01:00","relpermalink":"/publication/2005c_prototyping_filtersum_beamforming/","section":"publication","summary":"The work presented in this paper comes as a part of a project which aims at developing an auditory system for a mobile robot. It presents a sound source localization strategy which enables the sensing of signals within a direction of arrival and frequency domain of interest while rejecting other data. A rapid prototyping method is proposed to design filter-sum beamformers on the basis of convex optimization. This method is well-suited to robotics applications as it copes with real-time constraints and allows the localization of broadband signals such as human voice. Numerous simulation results are used to illustrate the reasoning.","tags":[],"title":"Prototyping Filter-Sum Beamformers for Sound Source Localization in Mobile Robotics","type":"publication"}]