<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>Robot audition - Sylvain Argentieri</title><meta name="description" content="“Blindness separate us from things but deafness from people” said Helen Keller, a famous American author who was the first&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://my.sylar.org/robot-audition/"><link rel="alternate" type="application/atom+xml" href="https://my.sylar.org/feed.xml"><link rel="alternate" type="application/json" href="https://my.sylar.org/feed.json"><meta property="og:title" content="Robot audition"><meta property="og:site_name" content="Sylvain Argentieri"><meta property="og:description" content="“Blindness separate us from things but deafness from people” said Helen Keller, a famous American author who was the first&hellip;"><meta property="og:url" content="https://my.sylar.org/robot-audition/"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://my.sylar.org/media/website/favicon.png" type="image/png"><link rel="stylesheet" href="https://my.sylar.org/assets/css/fontawesome-all.min.css?v=bbcde81f26378440dac4c3d195714389"><link rel="stylesheet" href="https://my.sylar.org/assets/css/style.css?v=589297fda6a2196a915f91cc98e2dd03"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://my.sylar.org/robot-audition/"},"headline":"Robot audition","datePublished":"2022-02-19T14:03","dateModified":"2022-02-20T18:40","description":"“Blindness separate us from things but deafness from people” said Helen Keller, a famous American author who was the first&hellip;","author":{"@type":"Person","name":"Sylvain Argentieri","url":"https://my.sylar.org/authors/sylvain-argentieri/"},"publisher":{"@type":"Organization","name":"Sylvain Argentieri"}}</script></head><body class="is-preload"><div id="wrapper"><div id="main"><div class="inner"><header id="header"><a class="logo" href="https://my.sylar.org/"><strong>Sylvain Argentieri</strong></a></header><article class="post"><header class="main post__header"><h1>Robot audition</h1></header><div class="post__inner post__entry"><figure class="post__image post__image--center"><img loading="lazy" src="https://my.sylar.org/media/posts/6/featured_huaca8b91f13bc14b487d5df59079fe7d0_147338_720x0_resize_q90_lanczos.jpg" alt="" width="720" height="240" sizes="(max-width: 48em) 100vw, 768px" srcset="https://my.sylar.org/media/posts/6/responsive/featured_huaca8b91f13bc14b487d5df59079fe7d0_147338_720x0_resize_q90_lanczos-xs.jpg 300w, https://my.sylar.org/media/posts/6/responsive/featured_huaca8b91f13bc14b487d5df59079fe7d0_147338_720x0_resize_q90_lanczos-sm.jpg 480w, https://my.sylar.org/media/posts/6/responsive/featured_huaca8b91f13bc14b487d5df59079fe7d0_147338_720x0_resize_q90_lanczos-md.jpg 768w"></figure><p><em>“Blindness separate us from things but deafness from people”</em> said Helen Keller, a famous American author who was the first deafblind person to obtain a Bachelor in Arts, in 1904. And indeed, being able to interpret an auditory scene from a robot is now a required capability when operating with humans, mainly interacting by speech with each others. Auditory scene analysis is a quite well-known research topic in Acoustics and Signal Processing, but considering its implication in Robotics, it is not as easy as expected to port all the already developments <em>inside</em> a robot. The robotic context exhibit original constraints like embeddability, real-time, reveberations, ego-noise, etc.</p><p>Two main paradigms are currently exploited in Robotics:</p><ul><li>on the one hand, <strong>array processing approaches</strong> exploit microphones array to exploit redundant audio information to perform sound source localization, source separation, source recognition in a very efficient way. Recent developments definitely show that this is the way to go to develop an efficient audio system in Robotics;</li><li>on the other hand, <strong>binaural approaches</strong> try to somewhat mimic the human auditory system, at least from an external point of view (two ears, generally with two external ears). Using only two ears in a Robotics context is still a very challenging task. But while one could question the choice to restrict ourself to only two ears, this is also a unique opportunity to test auditory models of human audition, and to stress the importance of action in the hearing process.</li></ul><p>Indeed, hearing is rarely a purely static task. For instance, one often makes small head movements to disambiguate sound location, or better sound recognition. This is specifically what I have been dealing with, i.e. <em><strong>active binaural audition</strong></em>. On this topic, I have mainly proposed contributions on:</p><ul><li>the <a href="https://my.sylar.org/binaural-cues-characterization/">characterization of binaural cues</a> used for sound localization and source recognition in realistic conditions,</li><li>the specific sound localization problem,</li><li>the use of the binaural movement to better sound localization,</li><li>and the building of multimodal representation of unknown environments through head movements.</li></ul></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on February 20, 2022</p></footer></article></div></div><div id="sidebar"><div class="inner"><nav id="menu"><header class="major"><h2>Menu</h2></header><ul><li><a href="https://my.sylar.org/biography/" target="_self">Home</a></li><li class="active-parent has-submenu"><a href="https://my.sylar.org/research-2/" target="_self" aria-haspopup="true" class="opener">Research</a><ul class="submenu level-2" aria-hidden="true"><li><a href="https://my.sylar.org/research-2/" target="_self">Overview</a></li><li><a href="https://my.sylar.org/interactive-perception/" target="_self">Interactive perception</a></li><li class="active"><a href="https://my.sylar.org/robot-audition/" target="_self">Robot audition</a></li></ul></li><li><a href="https://my.sylar.org/publications/" target="_self">Publications</a></li><li><a href="https://my.sylar.org/people/" target="_self">People</a></li><li class="has-submenu"><a href="https://my.sylar.org/overview/" target="_self" aria-haspopup="true" class="opener">Teaching</a><ul class="submenu level-2" aria-hidden="true"><li><a href="https://my.sylar.org/overview/" target="_self">Overview</a></li><li><a href="https://my.sylar.org/digital-signal-processing/" target="_self">Digital signal processing</a></li><li><a href="https://my.sylar.org/overview/" target="_self">ROS and experimental robotics</a></li><li><a href="https://my.sylar.org/overview/" target="_self">Sound source localization</a></li><li><a href="https://my.sylar.org/overview/" target="_self">Sensorimotor approaches to perception</a></li></ul></li><li><a href="https://my.sylar.org/tools/" target="_self">Tools</a></li><li><a href="https://my.sylar.org/stage-internship/" target="_self">Internship offer</a></li></ul></nav><section><header class="major"><h2>Get in touch</h2></header><p>You can find me <a href="https://osm.org/go/0BOd4gUuH?m=" target="_blank" rel="noopener">at ISIR</a>, office J02, or in the Master department, <a href="https://osm.org/go/0BOd4ggYU?m=">Esclangon building</a>, 2nd floor, office 219 (Faculty of Science &amp; Engineering, Sorbonne Université).</p><ul class="contact"><li class="icon solid fa-envelope"><a href="mailto:sylvain.argentieri_AT_sorbonne-universite.fr">my email</a></li><li class="icon solid fa-phone">(+33) 1 44 27 63 55</li><li class="icon solid fa-home">Sorbonne Université<br>Pyramide ISIR - T55/65, bureau J02<br>4 place Jussieu<br>75005 Paris, France</li></ul></section><footer id="footer"><p class="copyright">© Sylvain Argentieri - All rights reserved<a href="https://getpublii.com" target="_blank" rel="noopener"></a></p></footer></div></div></div><script src="https://my.sylar.org/assets/js/jquery.min.js?v=7c14a783dfeb3d238ccd3edd840d82ee"></script><script src="https://my.sylar.org/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://my.sylar.org/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://my.sylar.org/assets/js/util.min.js?v=cbdaf7c20ac2883c77ae23acfbabd47e"></script><script src="https://my.sylar.org/assets/js/main.min.js?v=448f4c9d4b4c374766a1cb76c3d88048"></script><script>var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};</script></body></html>