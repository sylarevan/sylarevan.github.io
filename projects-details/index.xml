<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects-details | Sylvain Argentieri</title>
    <link>https://my.sylar.org/projects-details/</link>
      <atom:link href="https://my.sylar.org/projects-details/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects-details</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 22 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://my.sylar.org/images/icon_hu1a01b3fab95c353a9499cb6a8a91062a_16677_512x512_fill_lanczos_center_2.png</url>
      <title>Projects-details</title>
      <link>https://my.sylar.org/projects-details/</link>
    </image>
    
    <item>
      <title>Binaural cues characterization</title>
      <link>https://my.sylar.org/projects-details/binaural_cues_characterization/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://my.sylar.org/projects-details/binaural_cues_characterization/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://my.sylar.org/project/robot_audition/&#34;&gt;&amp;laquo; back to Robot Audition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Almost everyone agree on the physical meaning of interaural cues used for horizontal sound source localization (time delay/phase difference and amplitude difference between the left and right ears signals), there is no clear agreement on the best way to estimate their value. For instance, here is short, clearly incomplete, list of the more classical estimation methods:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://my.sylar.org/img/projects/cues-list.png&#34; alt=&#34;The sensorimotor version of perception&#34;&gt;&lt;/p&gt;
&lt;p&gt;We then worked during &lt;a href=&#34;https://my.sylar.org/authors/karim-youssef/&#34;&gt;K. Youssef&lt;/a&gt; PhD on the comparison between the different definitions proposed in the literature, and on the evaluation of their performances evaluated through a positional classes separation criterion (in azimuth and distance), or in terms of speaker recognition rate. These works demonstrate the robustness of amplitude-bases cues w.r.t. reverberation (ands this was of course expected!), and show that cochlear frequency decomposition outperform classical FFT-based approaches, at a time where they were the most exploited in a Robotics context.&lt;/p&gt;
&lt;div style=&#34;text-align: right&#34;&gt; &lt;a href=&#34;https://my.sylar.org/projects-details/source_localization/&#34;&gt;Binaural sound source localization &gt;&gt;&lt;/a&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Binaural sound source localization</title>
      <link>https://my.sylar.org/projects-details/source_localization/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://my.sylar.org/projects-details/source_localization/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://my.sylar.org/project/robot_audition/&#34;&gt;&amp;laquo; back to Robot Audition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On the basis on our &lt;a href=&#34;https://my.sylar.org/projects-details/binaural_cues_characterization/&#34;&gt;binaural cues characterization&lt;/a&gt;, we exploited an artificial neural network (ANN) to learn and estimate the azimuth and distance of sound sources in the environment. But realistic robotics applications involve dynamic scenarios, where the relative position between the sources and the robot can evolve along time in a reverberant environment. We have then characterized &amp;mdash;during &lt;a href=&#34;https://my.sylar.org/authors/karim-youssef/&#34;&gt;K. Youssef&lt;/a&gt; PhD thesis&amp;mdash; the consequences of those changes in relative and absolute positions during the learning and test phases, and studied the generalization capabilities of the proposed ANN. More precisely, we highlighted the sensitivity of the learning phase to acoustical conditions (changes in the reverberation time) and binaural receiver position (different positions in a room). Multiconditionnal learning is thus shown mandatory, even if collecting data in all the various required conditions is far from beaing easy, especially when dealing with a binaural receiver on a mobile robot.&lt;/p&gt;
&lt;!--&lt;div style=&#34;text-align: right&#34;&gt; &lt;a href=&#34;https://my.sylar.org/projects-details/structuration_sensorimotor_flow/&#34;&gt;Structuration of the sensorimotor flow &gt;&gt;&lt;/a&gt;&lt;/div&gt;--&gt;</description>
    </item>
    
    <item>
      <title>Space dimension estimation</title>
      <link>https://my.sylar.org/projects-details/dimension_estimation/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://my.sylar.org/projects-details/dimension_estimation/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://my.sylar.org/project/interactive_perception/&#34;&gt;&amp;laquo; back to Interactive Perception&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within the sensorimotor paradigm, the question of &lt;em&gt;&lt;strong&gt;space&lt;/strong&gt;&lt;/em&gt; is a primary tremendous issue. While &lt;em&gt;space&lt;/em&gt; seems like a kind of universal, homogeneous and isotropic 3D container shared by all of us and our environment, discovering that &lt;em&gt;space&lt;/em&gt; actually exists only on the basis on what is actually available &amp;ldquo;from the inside&amp;rdquo; (i.e. the sensorimotor flow) is far from being intuitive. Especially since the sensorimotor flow isn&#39;t homogeneous, isotropic and 3D&amp;hellip;&lt;/p&gt;
&lt;p&gt;In particular, is it possible to rediscover that &lt;em&gt;space&lt;/em&gt; out there is a 3D space (at least from our point of view!), and that it can be characterize by 6 independent spatial variables corresponding to the 3 translations and 3 rotations we all know? This important question has already been raised by Henri Poincar√© at the end of the 19th century. Philipona showed in 2008 it was possible to recover space dimensionality from the sensorimotor flow, but only from infinitesimal movements. By using non-linear dimensional estimation techniques, we have shown &lt;a href=&#34;https://my.sylar.org/publication/2012c_non_linear_approach/&#34;&gt;in this paper&lt;/a&gt; that, while using realistic movements magnitudes, it was still possible to correctly estimate space dimension.&lt;/p&gt;
&lt;div style=&#34;text-align: right&#34;&gt; &lt;a href=&#34;https://my.sylar.org/projects-details/structuration_sensorimotor_flow/&#34;&gt;Structuration of the sensorimotor flow &gt;&gt;&lt;/a&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Structuration of the sensorimotor flow</title>
      <link>https://my.sylar.org/projects-details/structuration_sensorimotor_flow/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://my.sylar.org/projects-details/structuration_sensorimotor_flow/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://my.sylar.org/project/interactive_perception/&#34;&gt;&amp;laquo; back to Interactive Perception&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Having access to space dimension without any &lt;em&gt;a priori&lt;/em&gt; and on the basis on solely the sensorimotor flow is quite interesting, but far from being the most useful knowledge for a robotics agent. Our previous works on these topics were mainly rooted on sensory differential manifold, and the results were thus still dependent to changes in the environment configurations. This is a problem, since the notion of &lt;em&gt;space&lt;/em&gt; should not be dependent of what is actually in the agent environment&amp;hellip; We then tried to work on different ways to cope with these changes, first mainly &lt;a href=&#34;https://my.sylar.org/publication/2015j_learning_agents_spatial_configuration/&#34;&gt;from intuition&lt;/a&gt;, and then &lt;a href=&#34;https://my.sylar.org/publication/2017j_building_sensorimotor_tactile_space/&#34;&gt;more formally&lt;/a&gt;.&lt;/p&gt;
&lt;div style=&#34;text-align: right&#34;&gt; &lt;a href=&#34;https://my.sylar.org/projects-details/dimension_estimation/&#34;&gt;Space dimension estimation &gt;&gt;&lt;/a&gt;&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
